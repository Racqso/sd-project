{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'\\Users\\raqui\\sd-project\\coffee.csv') #import csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 16:39:18.887 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\raqui\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--at least one st.header with text (st.dataframe(df))\n",
    "--at least one Plotly Express histogram using st.write or st.plotly_chart\n",
    "--at least one Plotly Express scatter plot using st.write or st.plotly_chart\n",
    "--at least one checkbox using st.checkbox that changes the behavior of any of the above components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(20)) #print first 20 rows to get general idea of type of information included in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info()) #obtaining general information about the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See from above table following columns the 23 columns are as follows:\n",
    "Country, Region, Min. Altitude, Max. Altitude, Avrg. Altitude, Year, Owner, Coffee Type/Species, Variety, Processing Method, Flavor Score, Aftertaste Score, Acidity Score, Body Score, Balance Score, Uniformity Score, Sweetness Score, Moisture Score, Score Total, Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(\n",
    "    columns={\n",
    "        'Location.Country':'country',\n",
    "        'Location.Region':'region',\n",
    "        'Location.Altitude.Min':'altitude_min',\n",
    "        'Location.Altitude.Max':'altitude_max',\n",
    "        'Location.Altitude.Average':'altitude_avrg',\n",
    "        'Year':'year',\n",
    "        'Data.Owner':'owner',\n",
    "        'Data.Type.Species':'species',\n",
    "        'Data.Type.Variety':'variety',\n",
    "        'Data.Type.Processing method':'processing_method',\n",
    "        'Data.Production.Number of bags':'number_bags',\n",
    "        'Data.Production.Bag weight':'bag_weight',\n",
    "        'Data.Scores.Aroma':'aroma',\n",
    "        'Data.Scores.Flavor':'flavor',\n",
    "        'Data.Scores.Aftertaste':'aftertaste',\n",
    "        'Data.Scores.Acidity':'acidity',\n",
    "        'Data.Scores.Body':'body',\n",
    "        'Data.Scores.Balance':'balance',\n",
    "        'Data.Scores.Uniformity':'uniformity',\n",
    "        'Data.Scores.Sweetness':'sweetness',\n",
    "        'Data.Scores.Moisture':'moisture',\n",
    "        'Data.Scores.Total':'total_score',\n",
    "        'Data.Color':'color'\n",
    "    }\n",
    ")  # renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.columns) #print column names to check that changes were made successfully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Start to clean up and organize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['country'].sort_values(ascending = True).unique() #checking for any implicit duplicates in location column \n",
    "#note to self: (could also get the same results by df.country.sort_values(ascending = True).unique(), without needing the brackets and single quotations for country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't see any implicit duplicates above, so we move on to another step of cleaning the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isna().sum()) #check for absolute duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_replace=['region','owner','variety','processing_method','color']\n",
    "for column in columns_to_replace:\n",
    "    df[column] = df[column].fillna('unknown') # looping over column names and replacing missing values with 'unknown'\n",
    "# From the above information, decide to not focus on the categories with many unknown values, such as color, variety, \n",
    "#processing method, or region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isna().sum()) # counting missing values again to make sure there are no more missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig1 = px.scatter(df, x=\"country\", y=\"total_score\", title='Coffee total scores based on country', symbol='species')\n",
    "\n",
    "fig1.update_traces(marker=dict(size=10,\n",
    "                              line=dict(width=2,\n",
    "                                        color='Teal')),\n",
    "                  selector=dict(mode='markers'))\n",
    "\n",
    "data = [dict(\n",
    "    type='scatter',\n",
    "    x='country',\n",
    "    y='total_score',\n",
    "    mode='markers',\n",
    "    transforms=[dict(\n",
    "        type='filter',\n",
    "        target='y',\n",
    "        operation='>',\n",
    "        value=60\n",
    "    )]\n",
    "            )]\n",
    "\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = df['country'] == 'Honduras'\n",
    "honduras_filt_sum = df[filt].sum(axis=0, numeric_only=True)\n",
    "print(honduras_filt_sum)\n",
    "print()\n",
    "honduras_filt_mean = df[filt].mean(axis=0, numeric_only=True)\n",
    "print(honduras_filt_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can see from graph above that there is a very obvious outlier value for Honduras, which would significantly decrease the average coffee score if wanted an average for the country.\n",
    "Can also see that the dominant coffee species is Arabica rather than Robusta (only recorded for 5 countries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_update = df.drop(df.index[df['total_score'] == 0])\n",
    "\n",
    "fig2 = px.scatter(df_update, x=\"country\", y=\"total_score\", title='Coffee total scores based on country', symbol='species')\n",
    "\n",
    "fig2.update_traces(marker=dict(size=10,\n",
    "                              line=dict(width=2,\n",
    "                                        color='Teal')),\n",
    "                  selector=dict(mode='markers'))\n",
    "\n",
    "data = [dict(\n",
    "    type='scatter',\n",
    "    x='country',\n",
    "    y='total_score',\n",
    "    mode='markers',\n",
    "    transforms=[dict(\n",
    "        type='filter',\n",
    "        target='y',\n",
    "        operation='>',\n",
    "        value=60\n",
    "    )]\n",
    "            )]\n",
    "#Outliers can distort statistical analyses, affecting mean, variance, and other measures. \n",
    "#Removal improves data accuracy.\n",
    "fig2.show() \n",
    "# Can now see the removal of the zero value outlier from Honduras, thus showing a more accurate reflection of more meaningful \n",
    "#data values and if we wanted, we would have a much more accurate mean value, variance, etc. with regards to\n",
    "#the overall data and especially for Honduras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filt = df_update['country'] == 'Honduras'\n",
    "honduras_filt_sum = df_update[filt].sum(axis=0, numeric_only=True)\n",
    "print(honduras_filt_sum)\n",
    "print()\n",
    "honduras_filt_mean = df_update[filt].mean(axis=0, numeric_only=True)\n",
    "print(honduras_filt_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See from above updated table and graph--once the zero-value outlier was removed--that the score values for Honduras increase and the average total_score goes up by more than a whole point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_total_score_count = df.groupby('country')['total_score'].count() #number of entries per country \n",
    "print(country_total_score_count)\n",
    "print()\n",
    "#to see more statistically significant data with larger number of samples\n",
    "mean_count = country_total_score_count.sort_values().tail(5)  #will focus on top 5 countries with largest samples\n",
    "print(mean_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices_brazil = df.index[df['country']=='Brazil'].tolist()\n",
    "print()\n",
    "print(indices_brazil)\n",
    "print()\n",
    "print() #print cumulative mean total_score value for Brazil (then repeat for US, Colombia, Guatemala and Mexico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_brazil_total_score = len([1, 2, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 24, 27, 29, 54, 105, 120, 129, 130, 177, 186, 191, 193, 203, 215, 216, 218, 224, 255, 358, 465, 477, 588, 605, 618, 635, 674, 704, 764, 772, 775, 851, 859, 872, 878, 879, 882, 883, 884, 888, 889, 890, 892, 893, 894, 896, 905, 908, 922])\n",
    "print(sum_brazil_total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = df['country'] == 'Brazil'\n",
    "brazil_filt_sum = df[filt].sum(axis=0, numeric_only=True)\n",
    "print(brazil_filt_sum)\n",
    "print()\n",
    "brazil_filt_mean = df[filt].mean(axis=0, numeric_only=True)\n",
    "print(brazil_filt_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[[\"country\", \"total_score\"]].describe() # Overall statistical information for the total_score Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_update[[\"country\", \"total_score\"]].describe() # Overall statistical information for the total_score Series\n",
    "# Once remove zero-value outlier, see reduction in standard deviation, increase in minimum and therefore, mean and of course, \n",
    "#one less count of rows as one was removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_total_score_max = df.groupby('country')['total_score'].max()\n",
    "print(country_total_score_max)\n",
    "print()\n",
    "print(df.loc[[1, 5, 6], ['country', 'total_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = ['Brazil', 'United States', 'Colombia', 'Guatemala', 'Mexico']\n",
    "\n",
    "df_filtered = []\n",
    "\n",
    "for country in country_list:\n",
    "    country_base = [country] #will use country name variable as base\n",
    "    for score in column:\n",
    "        country_base.append(df['total_score'])\n",
    "    df_filtered.append(country_base)\n",
    "    \n",
    "print(df_filtered)\n",
    "\n",
    "table = pd.DataFrame(\n",
    "    df_filtered,\n",
    "    columns = ['country'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check what average for Honduras would be if do not remove outlier vs if do remove outlier value\n",
    "total_score_avrg = df.groupby('country')['total_score'].mean()\n",
    "print(total_score_avrg)\n",
    "print()\n",
    "highest_score_avrg = df.groupby('country')['total_score'].mean().tail(5)\n",
    "print(highest_score_avrg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See above from the coutnry entries count that there are 48 entries for Honduras. If we remove the outlier (the score of 0), then see that that the average score changes from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_total_scores = df[df['total_score'] > 90]\n",
    "print(highest_total_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can see from above result that an Ethiopian coffee scored the highest individual score. Next we want to see which country scored the highest overall average total_score, but we will first narrow down to the top 5 countries with the most entries (so as to have a higher number of samples from the respective countries for better representative scores).\n",
    "INSERT THE COUNTRY SPECIFIC INFORMATION/SCORES BELOW HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_total_scores = df['total_score'].max()\n",
    "print(max_total_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df['total_score'].sort_values(ascending=False).head(10)) #print top 10 total scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['total_score'].sort_values().head(10)) #see lowest 10 total scores -- see the Honduras outlier value of 0.00. \n",
    "#Can get rid of that so as not to completely throw off average score of that country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year.unique() #want to see which years are recorded, then can filter according to most recent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = px.histogram(df, x=\"year\")\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = px.histogram(df, x=\"country\")\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The countries that I will focus on will be those with higher sample sizes for a better idea of coffee character for those places, rather than such as those countries with only 1 or otherwise very few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4 = px.bar(df, x='altitude_avrg='aroma')\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can see that most data entries are below 2000m altitude. This can either indicate that coffee grows best at lower altitudes or it simply is not practical/not enough demand to warrant growing coffee at higher elevations, or there is simply not so much data about places that grow coffee in higher elevations, and hence, cannot come to a conclusion of whether altitude affects coffee characteristics based on this set of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above information, we see and can conclude that the highest rated coffee entry was from Ethiopia, but if we look only at the top 5 entries with the most recorded entries (i.e. Brazil, United States, Colombia, Guatemala, and Mexico) we see that amongst them, the country with the highest average total score was ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
